<?xml version='1.0' encoding='iso-8859-1' ?>
<documents><document>
<title>An Intelligent Robot and Augmented Reality Instruction System</title>
<publication-date>2016-05-01T00:00:00-07:00</publication-date>
<state>published</state>
<authors>
<author>
<email>creardon@utk.edu</email>
<institution>University of Tennessee - Knoxville</institution>
<lname>Reardon</lname>
<fname>Christopher</fname>
<mname>M.</mname>
</author>
</authors>
<keywords>
<keyword>robotics</keyword>
<keyword>artificial intelligence</keyword>
<keyword>augmented reality</keyword>
<keyword>disabilities</keyword>
</keywords>
<disciplines><discipline>Artificial Intelligence and Robotics</discipline>
</disciplines><abstract>&lt;p&gt;Human-Centered Robotics (HCR) is a research area that focuses on how robots can empower people to live safer, simpler, and more independent lives. In this dissertation, I present a combination of two technologies to deliver human-centric solutions to an important population. The first nascent area that I investigate is the creation of an Intelligent Robot Instructor (IRI) as a learning and instruction tool for human pupils. The second technology is the use of augmented reality (AR) to create an Augmented Reality Instruction (ARI) system to provide instruction via a wearable interface.&lt;/p&gt;
&lt;p&gt;To function in an intelligent and context-aware manner, both systems require the ability to reason about their perception of the environment and make appropriate decisions. In this work, I construct a novel formulation of several education methodologies, particularly those known as response prompting, as part of a cognitive framework to create a system for intelligent instruction, and compare these methodologies in the context of intelligent decision making using both technologies.&lt;/p&gt;
&lt;p&gt;The IRI system is demonstrated through experiments with a humanoid robot that uses object recognition and localization for perception and interacts with students through speech, gestures, and object interaction. The ARI system uses augmented reality, computer vision, and machine learning methods to create an intelligent, contextually aware instructional system. By using AR to teach prerequisite skills that lend themselves well to visual, augmented reality instruction prior to a robot instructor teaching skills that lend themselves to embodied interaction, I am able to demonstrate the potential of each system independently as well as in combination to facilitate students&#39; learning.&lt;/p&gt;
&lt;p&gt;I identify people with intellectual and developmental disabilities (I/DD) as a particularly significant use case and show that IRI and ARI systems can help fulfill the compelling need to develop tools and strategies for people with I/DD.&lt;/p&gt;
&lt;p&gt;I present results that demonstrate both systems can be used independently by students with I/DD to quickly and easily acquire the skills required for performance of relevant vocational tasks. This is the first successful real-world application of response-prompting for decision making in a robotic and augmented reality intelligent instruction system.&lt;/p&gt;</abstract>
<coverpage-url>https://trace.tennessee.edu/utk_graddiss/3737</coverpage-url>
<fulltext-url>https://trace.tennessee.edu/cgi/viewcontent.cgi?article=5160&amp;amp;context=utk_graddiss&amp;amp;unstamped=1</fulltext-url>
<label>3737</label>
<document-type>dissertation</document-type>
<type>article</type>
<articleid>5160</articleid>
<submission-date>2016-02-24T11:09:50-08:00</submission-date>
<publication-title>Doctoral Dissertations</publication-title>
<context-key>8209181</context-key>
<submission-path>utk_graddiss/3737</submission-path>
<fields>
<field name="advisor1" type="string">
<value>Lynne E. Parker</value>
</field>
<field name="advisor2" type="string">
<value>Bruce J. MacLennan, Bradley Vander Zanden, Mari Beth Coleman, Eric R. Wade</value>
</field>
<field name="degree_name" type="string">
<value>Doctor of Philosophy</value>
</field>
<field name="department" type="string">
<value>Computer Science</value>
</field>
<field name="embargo_date" type="date">
<value>2011-01-01T00:00:00-08:00</value>
</field>
<field name="instruct" type="string">
<value>1</value>
</field>
<field name="publication_date" type="date">
<value>2016-05-01T00:00:00-07:00</value>
</field>
</fields>
</document>
</documents>