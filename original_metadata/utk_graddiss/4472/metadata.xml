<?xml version='1.0' encoding='iso-8859-1' ?>
<documents><document>
<title>Analysis and Design of Communication Avoiding Algorithms for Out of Memory(OOM) SVD</title>
<publication-date>2017-05-01T00:00:00-07:00</publication-date>
<state>published</state>
<authors>
<author>
<email>kkabir@vols.utk.edu</email>
<institution>University of Tennessee, Knoxville</institution>
<lname>Kabir</lname>
<fname>Khairul</fname>
</author>
</authors>
<keywords>
<keyword>SVD</keyword>
<keyword>Bidiagonal</keyword>
<keyword>Band</keyword>
<keyword>out of memory</keyword>
<keyword>QR</keyword>
<keyword>tiled algorithm</keyword>
</keywords>
<disciplines><discipline>Numerical Analysis and Scientific Computing</discipline>
</disciplines><abstract>&lt;p&gt;Many applications — including big data analytics, information retrieval, gene expression analysis, and numerical weather prediction – require the solution of large, dense singular value decomposition (SVD). The size of matrices used in many of these applications is becoming too large to fit into into a computer’s main memory at one time, and the traditional SVD algorithms that require all the matrix components to be loaded into memory before computation starts cannot be used directly. Moving data (communication) between levels of memory hierarchy and the disk exposes extra challenges to design SVD for such big matrices because of the exponential growth in the gap between floating-point arithmetic rate and bandwidth for many different storage devices on modern high performance computers. In this dissertation, we have analyzed communication overhead on hierarchical memory systems and disks for SVD algorithms and designed communication-avoiding (CA) Out of Memory (OOM) SVD algorithms. By Out of Memory we mean that the matrix is too big to fit in the main memory and therefore must reside in external or internal storage. We have studied communication overhead for classical one-stage blocked SVD and two-stage tiled SVD algorithms and proposed our OOM SVD algorithm, which reduces the communication cost. We have presented theoretical analysis and strategies to design CA OOM SVD algorithms, developed optimized implementation of CA OOM SVD for multicore architecture, and presented its performance results.&lt;/p&gt;
&lt;p&gt;When matrices are tall, performance of OOM SVD can be improved significantly by carrying out QR decomposition on the original matrix in the first place. The upper triangular matrix generated by QR decomposition may fit in the main memory, and in-core SVD can be used efficiently. Even if the upper triangular matrix does not fit in the main memory, OOM SVD will work on a smaller matrix. That is why we have analyzed communication reduction for OOM QR algorithm, implemented optimized OOM tiled QR for multicore systems and showed performance improvement of OOM SVD algorithms for tall matrices.&lt;/p&gt;</abstract>
<coverpage-url>https://trace.tennessee.edu/utk_graddiss/4472</coverpage-url>
<fulltext-url>https://trace.tennessee.edu/cgi/viewcontent.cgi?article=5615&amp;amp;context=utk_graddiss&amp;amp;unstamped=1</fulltext-url>
<label>4472</label>
<document-type>dissertation</document-type>
<type>article</type>
<articleid>5615</articleid>
<submission-date>2016-10-07T22:01:11-07:00</submission-date>
<publication-title>Doctoral Dissertations</publication-title>
<context-key>9246364</context-key>
<submission-path>utk_graddiss/4472</submission-path>
<fields>
<field name="advisor1" type="string">
<value>Jack Dongarra</value>
</field>
<field name="advisor2" type="string">
<value>Michael Berry, Gregory Peterson, Bruce Ralston</value>
</field>
<field name="degree_name" type="string">
<value>Doctor of Philosophy</value>
</field>
<field name="department" type="string">
<value>Computer Science</value>
</field>
<field name="embargo_date" type="date">
<value>2011-01-01T00:00:00-08:00</value>
</field>
<field name="instruct" type="string">
<value>1</value>
</field>
<field name="publication_date" type="date">
<value>2017-05-01T00:00:00-07:00</value>
</field>
</fields>
</document>
</documents>