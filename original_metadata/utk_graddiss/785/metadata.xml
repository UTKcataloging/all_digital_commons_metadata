<?xml version='1.0' encoding='iso-8859-1' ?>
<documents><document>
<title>Scene Segmentation and Object Classification for Place Recognition</title>
<publication-date>2010-08-01T00:00:00-07:00</publication-date>
<state>published</state>
<authors>
<author>
<email>ccheng1@utk.edu</email>
<institution>The University of Tennessee</institution>
<lname>Cheng</lname>
<fname>Chang</fname>
</author>
</authors>
<keywords>
<keyword>Computer vision</keyword>
<keyword>image segmentation</keyword>
<keyword>object classification</keyword>
<keyword>robotics</keyword>
<keyword>place recognition</keyword>
</keywords>
<disciplines><discipline>Electrical and Computer Engineering</discipline>
</disciplines><abstract>&lt;p&gt;This dissertation tries to solve the place recognition and loop closing problem in a way similar to human visual system. First, a novel image segmentation algorithm is developed. The image segmentation algorithm is based on a Perceptual Organization model, which allows the image segmentation algorithm to ‘perceive’ the special structural relations among the constituent parts of an unknown object and hence to group them together without object-specific knowledge.&lt;/p&gt;
&lt;p&gt;Then a new object recognition method is developed. Based on the fairly accurate segmentations generated by the image segmentation algorithm, an informative object description that includes not only the appearance (colors and textures), but also the parts layout and shape information is built. Then a novel feature selection algorithm is developed. The feature selection method can select a subset of features that best describes the characteristics of an object class. Classifiers trained with the selected features can classify objects with high accuracy.&lt;/p&gt;
&lt;p&gt;In next step, a subset of the salient objects in a scene is selected as landmark objects to label the place. The landmark objects are highly distinctive and widely visible. Each landmark object is represented by a list of SIFT descriptors extracted from the object surface. This object representation allows us to reliably recognize an object under certain viewpoint changes. To achieve efficient scene-matching, an indexing structure is developed. Both texture feature and color feature of objects are used as indexing features. The texture feature and the color feature are viewpoint-invariant and hence can be used to effectively find the candidate objects with similar surface characteristics to a query object.&lt;/p&gt;
&lt;p&gt;Experimental results show that the object-based place recognition and loop detection method can efficiently recognize a place in a large complex outdoor environment.&lt;/p&gt;</abstract>
<coverpage-url>https://trace.tennessee.edu/utk_graddiss/785</coverpage-url>
<fulltext-url>https://trace.tennessee.edu/cgi/viewcontent.cgi?article=1898&amp;amp;context=utk_graddiss&amp;amp;unstamped=1</fulltext-url>
<label>785</label>
<document-type>dissertation</document-type>
<type>article</type>
<articleid>1898</articleid>
<submission-date>2010-07-22T08:22:55-07:00</submission-date>
<publication-title>Doctoral Dissertations</publication-title>
<context-key>1405503</context-key>
<submission-path>utk_graddiss/785</submission-path>
<fields>
<field name="advisor1" type="string">
<value>Mongi A. Abidi</value>
</field>
<field name="advisor2" type="string">
<value>Seddik M. Djouadi, Andreas Koschan, Hairong Qi, Timothy M. Young</value>
</field>
<field name="degree_name" type="string">
<value>Doctor of Philosophy</value>
</field>
<field name="department" type="string">
<value>Electrical Engineering</value>
</field>
<field name="embargo_date" type="date">
<value>2011-12-01T00:00:00-08:00</value>
</field>
<field name="publication_date" type="date">
<value>2010-08-01T00:00:00-07:00</value>
</field>
</fields>
</document>
</documents>