<?xml version='1.0' encoding='iso-8859-1' ?>
<documents><document>
<title>Validation Study of a Passive Image-Assisted Dietary Assessment Method with Automated Image Analysis Process</title>
<publication-date>2018-08-11T00:00:00-07:00</publication-date>
<state>published</state>
<authors>
<author>
<email>tchui@vols.utk.edu</email>
<institution>University of Tennessee</institution>
<lname>Chui</lname>
<fname>Tsz-Kiu</fname>
</author>
</authors>
<keywords>
<keyword>Dietary assessment</keyword>
<keyword>passive image-assisted dietary assessment</keyword>
<keyword>DietCam</keyword>
<keyword>automated image analysis</keyword>
<keyword>food identification</keyword>
<keyword>food shapes and complexities</keyword>
</keywords>
<abstract>&lt;p&gt;&lt;b&gt;Background:&lt;/b&gt; Image-assisted dietary assessment is being developed to enhance accuracy of dietary assessment. This study validated a passive image-assisted dietary assessment method, with an emphasis on examining if food shape and complexity influenced results.&lt;b&gt;Methods:&lt;/b&gt; A 2x2x2x2x3 mixed factorial design was used, with a between-subject factor of meal orders, and within-subject factors of food shapes, food complexities, meals, and methods of measurement, to validate the passive image-assisted dietary assessment method. Thirty men and women (22.7 ± 1.6 kg/m&lt;sup&gt;2&lt;/sup&gt;, 25.1 ± 6.6 years, 46.7% White) wore the Sony Smarteyeglass that automatically took images while two meals containing four foods representing four food categories were consumed. Images from the first 5 minutes of each meal were coded and then compared to DietCam for food identification. The comparison produced four outcomes: DietCam identifying food correctly in image (True Positive), DietCam incorrectly identifying food in image (False Positive), DietCam not identifying food in image (False Negative), or DietCam correctly identifying that the food is not in the image (True Negative). Participants’ feedback about the Sony Smarteyeglass was obtained by a survey.&lt;b&gt;Results:&lt;/b&gt; A total of 36,412 images were coded by raters and analyzed by DietCam, with raters coding that 92.4% of images contained foods and DietCam coding that 76.3% of images contained foods. Mixed factorial analysis of covariance revealed a significant main effect of percent agreement between DietCam and rater’s coded images [(F (3,48) = 8.5, p &lt; 0.0001]. The overall mean of True Positive was 22.2 ± 3.6 %, False Positive was 1.2 ± 0.4%, False Negative was 19.6 ± 5.0%, and True Negative was 56.8 ± 7.2%. True Negative was significantly (p &lt; 0.0001) different from all other percent agreement categories. No main effects of food shape or complexity were found. Participants reported that they were not willing to wear the Sony Smarteyeglass under different types of dining experiences.&lt;b&gt;Conclusion:&lt;/b&gt; DietCam is most accurate in identifying images that do not contain food. The platform from which the images are collected needs to be modified to enhance consumer acceptance.&lt;/p&gt;</abstract>
<coverpage-url>https://trace.tennessee.edu/utk_gradthes/5106</coverpage-url>
<fulltext-url>https://trace.tennessee.edu/cgi/viewcontent.cgi?article=6513&amp;amp;context=utk_gradthes&amp;amp;unstamped=1</fulltext-url>
<label>5106</label>
<document-type>thesis</document-type>
<type>article</type>
<articleid>6513</articleid>
<submission-date>2018-12-03T13:29:42-08:00</submission-date>
<publication-title>Masters Theses</publication-title>
<context-key>13414975</context-key>
<submission-path>utk_gradthes/5106</submission-path>
<fields>
<field name="advisor1" type="string">
<value>Hollie Anne Raynor</value>
</field>
<field name="advisor2" type="string">
<value>Marsha Lynn Spence, Jindong Tan</value>
</field>
<field name="degree_name" type="string">
<value>Master of Science</value>
</field>
<field name="department" type="string">
<value>Nutrition</value>
</field>
<field name="publication_date" type="date">
<value>2018-08-11T00:00:00-07:00</value>
</field>
</fields>
</document>
</documents>